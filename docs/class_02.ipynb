{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前回のコードのまとめ\n",
    "本日の演習では、こちらの学習コードを使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ArtIC-TITECH/b3-proj-2023/blob/main/docs/class_02.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch関連ライブラリ\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please update the path to your own directory.\n",
    "# path=/path/to/your_own  # Uncomment this line\n",
    "path = '../../work/data/cifar10'\n",
    "\n",
    "## Define Augmentation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "n_samples = len(trainset)\n",
    "trainsize = int(n_samples * 0.8)\n",
    "\n",
    "trainsubset, validsubset = torch.utils.data.random_split(trainset, [trainsize, n_samples-trainsize])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainsubset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(validsubset, batch_size=batch_size, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhekate/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhekate/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhekate/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     net(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/linearresnet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhekate/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhekate/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhekate/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhekate/artic/y-okoshi/b3-proj-2023/docs/class_02.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m) \u001b[39m# flatten all dimensions except batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/linearresnet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/linearresnet/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/linearresnet/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "## モデルが動作するかの確認\n",
    "input = torch.rand((1, 3, 32, 32)).to('cuda:0')\n",
    "with torch.no_grad():\n",
    "    net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(loader, model):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data[0].to('cuda:0'), data[1].to('cuda:0')\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    net.train()\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "def accuracy_batch(outputs, labels):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total = labels.size(0)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to('cuda:0'), data[1].to('cuda:0')\n",
    "\n",
    "        # 1. forward\n",
    "        outputs = net(inputs)\n",
    "        # 2. compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 3. reset parameter gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            ## Calculate validation accuracy\n",
    "            val_acc = accuracy(valloader, net)\n",
    "\n",
    "            ## Calculate batch accuracy\n",
    "            batch_acc = accuracy_batch(outputs=outputs, labels=labels)\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}, validation accuracy: {val_acc}, batch accuracy: {batch_acc}')\n",
    "\n",
    "            ## Call writer.add_scaler\n",
    "            \n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "accuracy(testloader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前回の課題\n",
    "\n",
    "`Net`クラスを修正して以下で定義されるモデルを実装してください。\\\n",
    "Conv2dは全て`padding=0`、`stride=1`で、MaxPool2dは`stride=2`で実装してください。\\\n",
    "それぞれの層のカーネルサイズは、テーブルの`Kernel Shape`を元に決定してください。\\\n",
    "それぞれの層のチャネル数は、入力チャネル、出力チャネルを参考に実装してください。\\\n",
    "\n",
    "```\n",
    "===================================================================================================================\n",
    "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape\n",
    "===================================================================================================================\n",
    "Net                                      [4, 3, 32, 32]            [4, 10]                   --\n",
    "├─Conv2d: 1-1                            [4, 3, 32, 32]            [4, 6, 28, 28]            [5, 5]\n",
    "│    └─weight                                                                                [3, 6, 5, 5]\n",
    "│    └─bias                                                                                  [6]\n",
    "|-ReLU                                   [4, 6, 28, 28]            [4, 6, 28, 28]\n",
    "├─MaxPool2d: 1-2                         [4, 6, 28, 28]            [4, 6, 14, 14]            2\n",
    "├─Conv2d: 1-3                            [4, 6, 14, 14]            [4, 16, 10, 10]           [5, 5]\n",
    "│    └─weight                                                                                [6, 16, 5, 5]\n",
    "│    └─bias                                                                                  [16]\n",
    "|-ReLU                                   [4, 16, 10, 10]           [4, 16, 10, 10]\n",
    "├─MaxPool2d: 1-4                         [4, 16, 10, 10]           [4, 16, 5, 5]             2\n",
    "├─Linear: 1-5                            [4, 400]                  [4, 120]                  --\n",
    "│    └─weight                                                                                [400, 120]\n",
    "│    └─bias                                                                                  [120]\n",
    "|-ReLU                                   [4, 120]                  [4, 120]\n",
    "├─Linear: 1-6                            [4, 120]                  [4, 84]                   --\n",
    "│    └─weight                                                                                [120, 84]\n",
    "│    └─bias                                                                                  [84]\n",
    "|-ReLU                                   [4, 84]                   [4, 84]\n",
    "├─Linear: 1-7                            [4, 84]                   [4, 10]                   --\n",
    "│    └─weight                                                                                [84, 10]\n",
    "│    └─bias                                                                                  [10]\n",
    "===================================================================================================================\n",
    "```\n",
    "\n",
    "### 結果の確認\n",
    "\n",
    "はじめに自身で定義したモデルが一致しているか確認したいと思います。\\\n",
    "まずは、Netを定義しているセルに移動して先週自分で実装したモデルと入れ替えてください。\n",
    "\n",
    "今回は出力が一致しているか確認するための検証データを用意しているのでそちらと結果が一致するか確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 検証用のデータのダウンロード\n",
    "!curl -L -o model_out.pt https://github.com/ArtIC-TITECH/b3-proj-2023/raw/main/resources/model_out.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下のセルを実行して何もエラーが発生しなければモデルが正しく実装できていることになります。\\\n",
    "結果が一致しない場合はモデルが正しく定義できているかもう一度確認してみましょう。\\\n",
    "(乱数のシードを一致させることで入出力の再現をしているため、モデルを定義する際の順序が異なると結果が一致しない可能性があります。層を実行する順番と定義する順番が一致するように注意してください。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "\n",
    "input = torch.rand((1, 3, 32, 32))\n",
    "net = Net()\n",
    "output = net(input)\n",
    "\n",
    "valid = torch.load('./model_out.pt')\n",
    "\n",
    "assert torch.isclose(valid, output).all(), \"Validation is failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答\n",
    "\n",
    "本日の演習ではこちらのモデルを使用するため、結果が一致しない場合は`Net`の定義をこちらのモデルに書き換えてください。\n",
    "\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboardを利用したモデルの可視化\n",
    "\n",
    "本日は`Tensorboard`というライブラリを使用した学習経過の視覚化を行います。\\\n",
    "学習過程を観察することでモデルの精度を上げるためのヒントを得られることがあります。\n",
    "\n",
    "まず、`Tensorboard`をGoogle Colabo上で利用可能にするには下記のコマンドを実行する必要があります。\n",
    "pytorchのライブラリをimportするセルの上に新しいセルを作成して、下記のコマンドをコピーした後に実行してください。\n",
    "\n",
    "### writerの定義\n",
    "\n",
    "tensorboardのSummaryWriterというクラスを用いてwriterを初期化します。\n",
    "下のセルにおいて、`path`を自身のGoogle Driveのパスに変更してください。\n",
    "\n",
    "```python\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "## Put your google drive path\n",
    "path = ''\n",
    "run_name = 'runs/cifar10_experiments1'\n",
    "run_dir = os.path.join(path, run_name)\n",
    "\n",
    "writer = SummaryWriter(run_dir)\n",
    "```\n",
    "\n",
    "別の実験を行う場合は`run_name`を`runs/cifar10_experimentsN`等に変更するようにしてください。\n",
    "実験を行いやすいようwriterを定義するセルの場所は適宜変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define writer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "## Put your google drive path\n",
    "path = ''\n",
    "run_name = 'runs/cifar10_experiments1'\n",
    "run_dir = os.path.join(path, run_name)\n",
    "\n",
    "writer = SummaryWriter(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboardを使ったモデル構造の記録\n",
    "\n",
    "`writer.add_xxx`という関数を呼び出すことでwriterにデータを記録することができます。\\\n",
    "(xxxは記録したいデータによって変わります。)\n",
    "\n",
    "まず初めに、モデル構造をtensorboardに記録してみましょう。\n",
    "次のセルを実行してみてください。\n",
    "\n",
    "`add_graph`という関数はモデル構造をtensorboardに記録するための関数で、第一引数がモデル、第二引数がモデルへの入力となります。\\\n",
    "前回も説明した通りCIFAR-10は$3\\times 32\\times 32$のテンソルなのでそれと同じ形状の乱数をここでは入力しています。\\\n",
    "(もちろんデータローダーから読み出した画像データを直接入力に使用しても問題ありません。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, torch.randn(1, 3, 32, 32).to('cuda:0'))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のセルを実行したら次のセルを実行してtensorboardを起動してください。\\\n",
    "logdirでデータが保存されているディレクトリを指定することができます。\\\n",
    "`./runs`は自身のGoogle Driveの配下にあるrunsディレクトリに変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に学習コードを利用して学習過程の視覚化を行います。\\\n",
    "学習コード中にwriterが使用できるよう、writerを定義しているセルをoptimizerを定義しているセルの下に移動してください。\\\n",
    "先ほども説明した通りrunの名前を`runs/cifar10_experiments2`などに書き換えてください。\n",
    "\n",
    "今回の演習では、ロスや精度などのスカラー値及び畳み込み層の重みパラメータなどのヒストグラムを表示します。\\\n",
    "tensorboardで使用する関数は[こちら](https://pytorch.org/docs/stable/tensorboard.html)にドキュメントがありますのでこちらも併せて確認してください。\n",
    "\n",
    "### Tensorboardを使ったスカラー値の記録\n",
    "\n",
    "スカラー値は`add_scalar`という関数を用います。\n",
    "第一引数には記録するデータ名、第二引数には実際に記録する値(グラフのy軸)、第三引数にはステップ数(グラフのx軸の値)を入力します。\n",
    "例えば、学習のi番目のイテレーションのlossを記録したい場合は学習コード中に次のような行を追加します。\n",
    "\n",
    "```python\n",
    "writer.add_scalar('loss', loss, i)\n",
    "```\n",
    "\n",
    "それでは実際の学習コードにスカラー値を記録していきましょう。\\\n",
    "今回の演習では、バリデーションデータセットの精度(`val_acc`)、学習データ1バッチの精度(`batch_acc`)、学習データの損失(`running_loss/100`)をtensorboardに記録してもらいます。\\\n",
    "学習コードの中のif文を編集して、100回に1回`val_acc`、`batch_acc`、`loss`をtensorboradのwriterに記録するようにコードを変更してください。\n",
    "```python\n",
    "...\n",
    "        if i % 100 == 99:\n",
    "            ## Calculate validation accuracy\n",
    "            val_acc = accuracy(valloader, net)\n",
    "\n",
    "            ## Calculate batch accuracy\n",
    "            batch_acc = accuracy_batch(outputs=outputs, labels=labels)\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}, validation accuracy: {val_acc}, batch accuracy: {batch_acc}')\n",
    "\n",
    "            ## Call writer.add_scaler\n",
    "            \n",
    "            running_loss = 0.0\n",
    "...\n",
    "```\n",
    "\n",
    "### Tensorboardを使ったヒストグラムの記録\n",
    "今回もまず初めにrunの名前を`runs/cifar10_experiments3`などに書き換えてください。\n",
    "\n",
    "今度は重みのヒストグラムを記録してみましょう。\\\n",
    "ヒストグラムは`add_histogram`という関数を用いて記録します。\\\n",
    "引数は`add_scalar`とほとんど同じです。第二引数にはスカラー値ではなくテンソルを入力します。\n",
    "\n",
    "```python\n",
    "writer.add_histogram('weight', value, i)\n",
    "```\n",
    "\n",
    "`net`内の全ての学習パラメータは次のように`named_parameters()`という関数を用いて得ることができます。\\\n",
    "それぞれのループで出力している`name`が学習パラメータの名前、`value`が学習パラメータになります。\n",
    "\n",
    "今回は、`named_parameters`という関数を用いて学習パラメータをtensorboardに記録していきましょう。\\\n",
    "スカラー値を記録する場合と同様にif文の中を編集してヒストグラムを追加してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 3, 5, 5])\n",
      "conv1.bias torch.Size([6])\n",
      "bn1.weight torch.Size([6])\n",
      "bn1.bias torch.Size([6])\n",
      "conv2.weight torch.Size([16, 6, 5, 5])\n",
      "conv2.bias torch.Size([16])\n",
      "bn2.weight torch.Size([16])\n",
      "bn2.bias torch.Size([16])\n",
      "fc1.weight torch.Size([120, 400])\n",
      "fc1.bias torch.Size([120])\n",
      "fc2.weight torch.Size([84, 120])\n",
      "fc2.bias torch.Size([84])\n",
      "fc3.weight torch.Size([10, 84])\n",
      "fc3.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, value in net.named_parameters():\n",
    "    print(name, value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習\n",
    "モデル構造を変更して(層を増やす、チャネルを増やす、カーネルサイズを変更する、[BatchNorm](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)層を追加するなど)CIFAR-10の精度がどう変化するか確認してみましょう。\\\n",
    "授業の最後にバリデーションデータセットで最も精度が高いモデルを使用してテストデータセットの精度を測ってみましょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linearresnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
