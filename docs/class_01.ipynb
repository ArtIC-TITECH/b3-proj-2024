{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ArtIC-TITECH/b3-proj-2023/blob/main/docs/class_01.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNを利用したCIFAR-10データセットでの学習\n",
    "\n",
    "次の流れで畳み込みニューラルネットワーク(CNN)を使用した10クラス分類の教師あり学習の実装を以下の順番で行なっていきます。\n",
    "- データセットの作成(今回はCIFAR-10というデータセットを使用します)\n",
    "- モデルの作成\n",
    "- 損失関数、最適化関数の定義\n",
    "- モデルの学習\n",
    "- モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、本日の演習で使用するライブラリをインポートします。\\\n",
    "今回の演習では`pytorch`と呼ばれるライブラリを使用してニューララルネットワークの実装を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch関連ライブラリ\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10データローダーの作成\n",
    "\n",
    "### CIFAR-10とは\n",
    "\n",
    "- 合計で6万枚のRGB画像(32x32)を含むデータセット\n",
    "- クラス数は10クラス(各クラス学習用5000枚、評価用1000枚)\n",
    "\n",
    "### データセットの作成\n",
    "\n",
    "pytorchでは、torchvisionのライブラリを使用することで`torchvision.datasets.CIFAR10`のように事前に決められた[データセット](https://pytorch.org/vision/0.8/datasets.html)を使用することができます。\n",
    "\n",
    "`root`はデータセットを保存するパスを指定します。\n",
    "今回は`path`という変数を使用しているため、`path`を書き換えることでデータの保存先を各自変更してください。\n",
    "例えば、Google Driveの配下の`b3_proj_2023/data`に学習用データを保存する場合は`path`を\n",
    "```python\n",
    "path = \"./drive/My Drive/Colab Notebooks/b3_proj_2023/data\"\n",
    "```\n",
    "のように変更します。\n",
    "(このように自身のGoogle Drive上に保存することで次回以降にデータを再度ダウンロードする必要がなくなるので便利です。)\n",
    "\n",
    "`train=True|False`で学習データか評価データかを指定することができます。 \\\n",
    "また、`transform`でデータ変換やデータオーグメンテーションを指定することができます。\n",
    "データ変換は複数同時に適用することがほとんどで、そのような場合は`transforms.Compose`を使用して複数のデータ変換を一連の処理として指定します。\n",
    "```python\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    ...\n",
    "     ])\n",
    "```\n",
    "のようにpythonのリストで指定し、データを読み込む際に上から順番に実行されます。\n",
    "適用可能な関数の一覧は[こちら](https://pytorch.org/vision/main/transforms.html)を参照してください。\n",
    "\n",
    "## データローダーの作成\n",
    "\n",
    "データセットに含まれるデータ数は非常に大きく、一度にメモリに読み込むことは難しい場合が多いです。\\\n",
    "そのため、そこで一度に読み出すデータの数を減らすことで計算負荷を減らしています。\\\n",
    "これをミニバッチと呼び、ロードするデータ数をバッチサイズと呼びます。\n",
    "\n",
    "pytorchでは、こうしたバッチ処理を`DataLoader`というクラスを用いて行います。\\\n",
    "`DataLoader`は`batch_size`という引数で一度に読み出すデータの数を指定することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please update the path to your own directory.\n",
    "# path=/path/to/your_own  # Uncomment this line\n",
    "path = '../../work/data/cifar10'\n",
    "\n",
    "## Define Augmentation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     ])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット・データローダーの確認\n",
    "\n",
    "先ほどのデータセットにどのようなデータが保存されているのか確認します。\n",
    "\n",
    "`images`は$[B\\times 3\\times 32\\times 32]$のテンソルでモデルの入力に使用します。\\\n",
    "また、`labels`は$[B]$のテンソルで学習のラベルとして使われます。ここで、$B$はバッチサイズを表します。\n",
    "\n",
    "下のセルを実行すると変数`batch_size`で指定した数と同じ枚数の画像が出力されるのがわかるかと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "torch.manual_seed(15)\n",
    "\n",
    "def imshow(imgs, labels):\n",
    "    imgs = imgs / 2 + 0.5     # unnormalize\n",
    "    npimg = imgs.numpy()\n",
    "    for i, (img, label) in enumerate(zip(npimg, labels)):\n",
    "        plt.subplot(1, batch_size, i+1)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "        label = label.item()\n",
    "        plt.title(f\"{classes[label]}({label})\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(images, labels)\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習\n",
    "\n",
    "- データ変換に正規化を追加してください。\n",
    "- バッチサイズを4に変更した場合に出力がどう変化するか確認してください。\n",
    "- ランダムに上下を反転させるデータ変換を追加してください。(任意)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの作成\n",
    "ここでは、推論に使用するモデルの作成を行います。\n",
    "\n",
    "モデルを作成する前にニューラルネットワークで広く用いられるモデルの構成要素について簡単に説明します。\n",
    "\n",
    "### 全結合層\n",
    "<img src=\"../resources/class_01/fully_connected.png\" width=\"10%\">\n",
    "\n",
    "全結合層とは、入力と出力が全て重みによって結合されている層を指します。\\\n",
    "図では、一次元で表していますが、`pytorch`ではバッチ処理が行われるため実際は2次元の入力に対して処理が行われます。\\\n",
    "そのため、入力$\\mathbf{x} \\in \\mathbb{R}^{B\\times C_{\\rm in}}$に対して、重み$W\\in\\mathbb{R}^{C_{\\rm in}\\times C_{\\rm out}}$とバイアス$\\mathbf{B} \\in \\mathbb{R}^{B\\times C_{\\rm out}}$を用いて出力$y\\in\\mathbb{R}^{B\\times C_{\\rm out}}$は次のように計算されます。\n",
    "$$\\mathbf{y} = \\mathbf{x}\\mathbf{W} + \\mathbf{B}$$\n",
    "ここで、$B$はバッチサイズ、$C_{\\rm in}$、$C_{\\rm out}$は入力チャネル、出力チャネル数を表しています。\n",
    "\n",
    "`pytorch`では`nn.Linear`というクラスで実装されています。\\\n",
    "`in_features`で入力のチャネル数、`out_features`で出力のチャネル数を指定します。\n",
    "\n",
    "例えば、入力チャネルが$4$、出力チャネルが$10$の全結合層は次のように実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "input = torch.rand((4, 3))\n",
    "print(f'Input Shape is {input.shape}')\n",
    "linear = nn.Linear(in_features=3, out_features=10)\n",
    "output = linear(input)\n",
    "print(f'Output Shape is {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習\n",
    "上のセルを修正して入力チャネルが5、出力チャネルが15の線形層を`nn.Linear`を用いて実装してください。\\\n",
    "このとき、入力のバッチサイズを4とし、線形層の入力チャネルと入力データのチャネル数を揃える必要があることに注意してください。\n",
    "\n",
    "\n",
    "### 畳み込み層\n",
    "<img src=\"../resources/class_01/conv1d.png\" width=\"30%\">\n",
    "\n",
    "全結合層では全ての入力チャネルと出力チャネルが重みで結合されていたのに対し、畳み込み層では入力に対してカーネルをストライドさせることで出力を計算します。\\\n",
    "そのため、出力のサイズは、カーネルサイズ、ストライド、パディングによって決定されます。\\\n",
    "画像では1次元のデータに対する1次元の畳み込みを例にしていますが、画像のデータセットでは4次元の入力に対し2次元の畳み込みを行うことが一般的です。\\\n",
    "この場合カーネルは$[C_{\\rm out}, C_{\\rm in}, k_{\\rm h}, k_{\\rm w}]$の4次元のテンソルで定義され、このカーネルを画像の縦横方向にストライドさせることで計算を行います。\n",
    "\n",
    "例えば、入力サイズが$[4, 3, 10, 10]$のデータに対して、出力チャネル6、カーネルサイズ3、パディングおよびストライドが1の畳み込みは次のように実装されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "input = torch.rand((4, 3, 10, 10))\n",
    "print(f'Input Shape is {input.shape}')\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, padding=1, stride=1)\n",
    "output = conv2d(input)\n",
    "print(f'Output Shape is {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習\n",
    "上のセルを修正して入力チャネルが5、出力チャネルが10のカーネルサイズが5、パディングが0、ストライドが1のConvを実装してください。\\\n",
    "このとき、入力のバッチサイズを4とし、入力チャネルと入力データのチャネル数を揃える必要があることに注意してください。\\\n",
    "出力のサイズが変化していることを確認してください。\n",
    "\n",
    "### プーリング層\n",
    "\n",
    "プーリング層は畳み込み層と同様にカーネルを画像の$H$、$W$方向に動かしながら処理を行いますが、次の2点で畳み込み層と異なります。\n",
    "- チャネル間の情報を集約しない\n",
    "- カーネルは重みではなく決まった処理が行われる\n",
    "    - MaxPool2dでは、カーネル内の最大値が出力される\n",
    "    - AvgPool2dでは、カーネル内の平均値が出力される\n",
    "\n",
    "例えば、カーネルサイズ$2$、ストライド$2$のMaxPool2dは次のように使用します。\\\n",
    "入出力を比較すると$2\\times2$のカーネルの中から最大値が選ばれていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "input = torch.rand((4, 3, 8, 8))\n",
    "print(input[0][0])\n",
    "pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "output = pool(input)\n",
    "\n",
    "print(output[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 活性化関数\n",
    "活性化関数とは、入力に対して非線形処理を適用しニューラルネットワークの表現力を向上させるために使用する関数です。\n",
    "\n",
    "活性化関数には様々な種類がありますが、今回の演習では`ReLU`関数を非線形関数として用います。\\\n",
    "次のコードは入力に対して`ReLU`を適用したもので、$0$以下の入力が全て$0$となることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "input = torch.randn(100,)\n",
    "act = nn.ReLU()\n",
    "output = act(input)\n",
    "plt.plot(input.sort().values, output.sort().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで説明した4つの構成要素を用いてニューラルネットワークは次のように実装されます。\\\n",
    "ここでは、畳み込み1層、プーリング層1層、全結合層1層のニューラルネットワークを実装しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.act = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=6*14*14, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.conv1(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実際にモデルを動かしてみよう\n",
    "\n",
    "ここでは乱数を入力としてモデルを動かしてみます。\n",
    "ニューラルネットワークは、入力サイズ$(B, C, H, W)$のテンソルを入力として、$(B, \\rm{Cls})$を出力とします。\\\n",
    "ここで$B$はバッチサイズ、$C$は入力チャネル数(RGB画像の場合は3チャネル)、$H$, $W$は画像の幅と高さになります。CIFAR-10データセットの場合は、$H=W=32$です。\\\n",
    "$\\rm{Cls}$は出力のクラス数を表し、CIFAR-10は10クラスを出力します。\\\n",
    "ここでは、$(B, C, H, W) = (1, 3, 32, 32)$の乱数を入力としてモデルの推論を行います。\\\n",
    "実際にコードを実行すると(1, 10)の出力が得られると思います。出力の各要素がそれぞれのクラスの予測値となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "\n",
    "input = torch.rand((1, 3, 32, 32))\n",
    "net = Net()\n",
    "output = net(input)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習\\\n",
    "`Net`クラスを修正して以下で定義されるモデルを実装してください。\\\n",
    "Conv2dは全て`padding=0`、`stride=1`で、MaxPool2dは`stride=2`で実装してください。\\\n",
    "それぞれの層のカーネルサイズは、テーブルの`Kernel Shape`を元に決定してください。\\\n",
    "それぞれの層のチャネル数は、入力チャネル、出力チャネルを参考に実装してください。\\\n",
    "最終層以外のConv, Linear層の後には\n",
    "\n",
    "```\n",
    "===================================================================================================================\n",
    "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape\n",
    "===================================================================================================================\n",
    "Net                                      [4, 3, 32, 32]            [4, 10]                   --\n",
    "├─Conv2d: 1-1                            [4, 3, 32, 32]            [4, 6, 28, 28]            [5, 5]\n",
    "│    └─weight                                                                                [3, 6, 5, 5]\n",
    "│    └─bias                                                                                  [6]\n",
    "|-ReLU                                   [4, 6, 28, 28]            [4, 6, 28, 28]\n",
    "├─MaxPool2d: 1-2                         [4, 6, 28, 28]            [4, 6, 14, 14]            2\n",
    "├─Conv2d: 1-3                            [4, 6, 14, 14]            [4, 16, 10, 10]           [5, 5]\n",
    "│    └─weight                                                                                [6, 16, 5, 5]\n",
    "│    └─bias                                                                                  [16]\n",
    "|-ReLU                                   [4, 16, 10, 10]           [4, 16, 10, 10]\n",
    "├─MaxPool2d: 1-4                         [4, 16, 10, 10]           [4, 16, 5, 5]             2\n",
    "├─Linear: 1-5                            [4, 400]                  [4, 120]                  --\n",
    "│    └─weight                                                                                [400, 120]\n",
    "│    └─bias                                                                                  [120]\n",
    "|-ReLU                                   [4, 120]                  [4, 120]\n",
    "├─Linear: 1-6                            [4, 120]                  [4, 84]                   --\n",
    "│    └─weight                                                                                [120, 84]\n",
    "│    └─bias                                                                                  [84]\n",
    "|-ReLU                                   [4, 84]                   [4, 84]\n",
    "├─Linear: 1-7                            [4, 84]                   [4, 10]                   --\n",
    "│    └─weight                                                                                [84, 10]\n",
    "│    └─bias                                                                                  [10]\n",
    "===================================================================================================================\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数とオプティマイザの定義\n",
    "\n",
    "損失関数$L$とはモデルの予測値と正解ラベルの誤差を計算するための関数です。\\\n",
    "損失関数は`CrossEntropyLoss`というラベルデータの確率分布と出力の確率分布の誤差を計算する関数が主に使用されます。\\\n",
    "また、オプティマイザーとはパラメータを更新するための関数で、画像認識では`SGD`や`Adam`などが広く使用されています。\n",
    "\n",
    "今回の演習では、`SGD`をオプティマイザとして使用します。\n",
    "`SGD`の第一引数は更新するパラメータを指定しています。\\\n",
    "第二引数は学習率と呼ばれ、一度に更新するパラメータの大きさを調整しています。\\\n",
    "`momentum`や、今回は使われていませんが`weight_decay`といった引数はニューラルネットワークの学習を安定させたり過学習を抑制するために使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークの学習\n",
    "\n",
    "では、先ほど定義した損失関数とoptimizerを使用して実際にニューラルネットワークの学習を行いましょう。\\\n",
    "最初に説明した通り、ニューラルネットワークの学習はミニバッチ学習と呼ばれるデータセットの一部のデータを使用してパラメータを更新する作業を繰り返し行います。\\\n",
    "データセット内の全てのデータが学習に使用されるイテレーションの数を1エポックと呼び、複数エポック学習することでパラメータの最適化を行います。\\\n",
    "\n",
    "各イテレーションでは、次の4つの処理を主に行います。\n",
    "- モデルの推論(順伝播)\n",
    "    - ミニバッチ入力に対してモデルが予測値を出力します。\n",
    "- 損失の計算\n",
    "    - モデルの予測値と正解ラベルの誤差を計算します。\n",
    "- 勾配のリセット\n",
    "    - 前のイテレーションでパラメータの更新に使用した勾配のリセット。\n",
    "- 勾配の計算(逆伝播)\n",
    "    - 損失を元に各パラメータの勾配計算を行います。\n",
    "- パラメータの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 1. forward\n",
    "        outputs = net(inputs)\n",
    "        # 2. compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 3. reset parameter gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータを使用した検証\n",
    "では、先ほど学習したモデルを使用して新しい検証用データに対する精度を測ってみましょう。\n",
    "\n",
    "まずは、評価に使うデータをテストデータセットからロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(images, labels)\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほどロードしたデータを用いて推論を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): # Gradient計算を無効にします\n",
    "    outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測結果を出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果はどうでしたか。\n",
    "次は、テストデータセットを全て用いて精度を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスごとの精度も確認してみましょう。\n",
    "どのクラスの精度が一番高かったですか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデルは、次のように保存することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存したモデルは次のようにすることで、保存したパラメータを使用することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に学習をGPUを用いて行うように変更します。\\\n",
    "GPUを使用して学習するためには、モデルとデータをGPUに送る必要があります。\n",
    "\n",
    "まずは、GPUが使用可能か確認します。\n",
    "次のコードで`False`という結果が出たらGoogle Colaboratoryのランタイムを`GPU`に変更してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUが使用可能であることがわかったら、モデルとデータをGPUで利用できるようにします。\n",
    "まず、deviceという変数を一番初めのpythonセルに追加してください。\n",
    "\n",
    "```python\n",
    "## Pytorch関連ライブラリ\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = 'cuda:0' # 0番目のGPUをdeviceとして指定\n",
    "```\n",
    "\n",
    "モデルの定義部分と、入力及びラベルデータを次のように変更してください。\n",
    "\n",
    "```python\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "```\n",
    "\n",
    "```python\n",
    "# inputs, labels = data\n",
    "inputs, labels = data[0].to(device), data[1].to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宿題\n",
    "**課題1**: VGG11を実装して評価してください。\\\n",
    "(**課題2**): データ拡張、モデルなどを変更してCIFAR-10の精度を向上させてください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linearresnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
