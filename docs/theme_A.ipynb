{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ArtIC-TITECH/b3-proj-2024/blob/main/docs/theme_A.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch関連ライブラリ\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "- 量子化関数の実装\n",
    "- 量子化を適用したモデルの評価\n",
    "- 再学習の実装\n",
    "    - 再学習用の逆伝播の実装\n",
    "    - モデルの再学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量子化関数の実装\n",
    "\n",
    "量子化とは、モデルのパラメータや入力を低ビットで表現する手法です。\\\n",
    "低ビットで表現することで計算コストやモデルサイズを削減することができます。\\\n",
    "実際に、エッジデバイス上でニューラルネットワークを使用する際は量子化適用することがほとんどです。\\\n",
    "今回はFP32の値をIntにする量子化を演習を通して行いたいと思います。\\\n",
    "量子化の中でもUniform Quantizationと呼ばれる量子化の幅を均一にした量子化が頻繁に用いられ、\\\n",
    "入力$r$に対して出力$\\hat{r}$は次のように計算されます。\n",
    "\n",
    "$Q(r) = \\rm{Int}(r/S) - Z$\n",
    "\n",
    "$\\hat{r} = S(Q(r) + Z)$\n",
    "\n",
    "$Z$は$0$がどの値に量子化されるかを決めます。非対称の入力を量子化する際はこちらの値を使用して調整します。\n",
    "$S$は量子化のスケールファクターを表しており、$\\alpha$, $\\beta$を量子化範囲の最小値、最大値として\n",
    "\n",
    "$S = \\frac{\\beta - \\alpha}{2^b - 1}$\n",
    "\n",
    "で計算されます。ここで、$b$は量子化ビット幅と呼ばれます。\\\n",
    "$S$を用いることで量子化の幅を調整して、実際の値と近い値を選ぶことができます。\\\n",
    "今回の演習では簡単のため$\\alpha = -\\beta = \\max(|\\max(r)|, |\\min(r)|), Z=0$として量子化を行います。\\\n",
    "(余裕がある方は$\\alpha, \\beta$の範囲を変えて実験してみてください。)\\\n",
    "では、実際にpytorchのテンソルを量子化してみましょう。量子化幅を調整できるよう$r$と$b$を引数として実装してみてください。\n",
    "\n",
    "pytorchのテンソルの最大値、最小値は次のように得ることができます。\n",
    "\n",
    "```python\n",
    "x = torch.rand(1000) # initialize pytorch tensor\n",
    "x_max, x_min  = x.max(), x.min()\n",
    "```\n",
    "\n",
    "数式上の$\\rm{Int(x)}$関数はpytorch上では`round`という関数を使用します。\n",
    "```python\n",
    "# x.clamp 値域を[-2**{b-1}-1, 2**{b-1}]に制限 (量子化の範囲)\n",
    "# x.round Intに丸め込みをする関数\n",
    "x_int = x.round(x.clamp(x, -2**{b-1}-1, 2**{b-1}))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r: real value (fp32), b: bit-width\n",
    "def quantization(r: torch.Tensor, b=4):\n",
    "    # Implement S\n",
    "    # Implement hat_r\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装が終わったら入出力のplotを行ってみましょう。\n",
    "下のセルを実行することで横軸に量子化前の値、縦軸に量子化後の値をplotすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(100)\n",
    "r = torch.randn(1000).sort()[0]\n",
    "hat_r = quantization(r, b=3)\n",
    "\n",
    "plt.plot(r, hat_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習\n",
    "- ${\\alpha, \\beta} = {+\\rm{std}(x), -\\rm{std}(x)}$に変更して入出力がどう変化するか確認してください。\n",
    "- ビット幅をb=8, 4, 2と変更して入出力がどう変化するか確認してください。\n",
    "\n",
    "### 量子化を利用したモデルの作成\n",
    "\n",
    "次に先ほど実装した関数を畳み込み層と線形層に適用してみましょう。\\\n",
    "ここでは、pytorchで実装されているConv2dとLinearクラスを継承した\\\n",
    "QuantConv2dとQuantLinearというクラスを作成します。\\\n",
    "下のセルでinput_quantizerとweight_quantizerを先ほど実装した量子化関数に変更してください。\\\n",
    "本来であればバイアスも量子化する必要がありますが、今回は簡単のため入力と重みのみを量子化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import torch.nn as nn\n",
    "from torch.nn.common_types import _size_2_t\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QuantConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: _size_2_t, stride: _size_2_t = 1, padding: _size_2_t | str = 0, dilation: _size_2_t = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None:\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\n",
    "        self.weight_quantizer = quantization\n",
    "        # self.weight_quantizer = Quantization\n",
    "        self.input_quantizer = quantization\n",
    "        # self.input_quantizer = Quantization\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._conv_forward(self.input_quantizer.apply(x), self.weight_quantizer.apply(self.weight), self.bias)\n",
    "\n",
    "class QuantLinear(nn.Linear):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None:\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        self.weight_quantizer = quantization\n",
    "        self.input_quantizer = quantization\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.linear(self.input_quantizer.apply(x), self.weight_quantizer.apply(self.weight), self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = QuantConv2d(3, 32, 5)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.conv2 = QuantConv2d(32, 64, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # self.fc1 = QuantLinear(64 * 5 * 5, 120)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 120)\n",
    "        # self.fc2 = QuantLinear(120, 84)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = QuantLinear(84, 10)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class QuantizedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = QuantConv2d(3, 32, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = QuantConv2d(32, 64, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = QuantLinear(64 * 5 * 5, 120)\n",
    "        self.fc2 = QuantLinear(120, 84)\n",
    "        self.fc3 = QuantLinear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to('cuda:0')\n",
    "quantized_net = QuantizedNet().to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "量子化する前の学習済みの重みを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o model_out.pt https://github.com/ArtIC-TITECH/b3-proj-2023/raw/main/resources/class_03/pretraint.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('../resources/class_03/pretrain.pth'))\n",
    "quantized_net.load_state_dict(torch.load('../resources/class_03/pretrain.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータセットを使用して精度を測ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please update the path to your own directory.\n",
    "# path=/path/to/your_own  # Uncomment this line\n",
    "path = '../../work/data/cifar10'\n",
    "\n",
    "## Define Augmentation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "n_samples = len(trainset)\n",
    "trainsize = int(n_samples * 0.8)\n",
    "\n",
    "trainsubset, validsubset = torch.utils.data.random_split(trainset, [trainsize, n_samples-trainsize])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainsubset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(validsubset, batch_size=batch_size, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(loader, model):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data[0].to('cuda:0'), data[1].to('cuda:0')\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    net.train()\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "def accuracy_batch(outputs, labels):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total = labels.size(0)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(testloader, net))\n",
    "print(accuracy(testloader, quantized_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ビット幅を小さくすると精度が下がることがわかると思います。\\\n",
    "このような場合はfine-tuningと呼ばれる再学習を行うことで精度を回復させることができます。\\\n",
    "しかし、量子化のグラフを見るとわかるように量子化を適用する関数は任意の点で勾配が$0$になってしまうため、\\\n",
    "このままでは学習することができません。そこで、`torch.autograd.Function`クラスを継承したクラスを作成して、\\\n",
    "勾配を近似する必要があります。今回はStraight Through Estimatorと呼ばれる勾配を恒等関数の勾配(つまり全ての入力に対して微分値が$1$になる関数)に近似する方法を用いて量子化関数の微分を定義します。\n",
    "\n",
    "`quantization`の関数を定義したセルの下に次のようなクラスを作成して量子化の順伝播と逆伝播を定義してください。\n",
    "\n",
    "```python\n",
    "class Quantization(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        # Call quantization function\n",
    "        return quantization(x)\n",
    "    \n",
    "    def backward(ctx, x):\n",
    "        # Implement backward of identity function\n",
    "        return \n",
    "\n",
    "```\n",
    "\n",
    "Functionクラスを継承したクラスは`apply`という関数を用いて呼び出すのでQuantConv2dとQuantLinearを次のように変更してください。\n",
    "\n",
    "```python\n",
    "class QuantConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: _size_2_t, stride: _size_2_t = 1, padding: _size_2_t | str = 0, dilation: _size_2_t = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None:\n",
    "        ...\n",
    "        self.weight_quantizer = Quantization\n",
    "        self.input_quantizer = Quantization\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._conv_forward(self.input_quantizer.apply(x), self.weight_quantizer.apply(self.weight), self.bias)\n",
    "```\n",
    "\n",
    "\n",
    "実装が終わったらモデルの再学習を行ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(quantized_net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_net.train()\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to('cuda:0'), data[1].to('cuda:0')\n",
    "\n",
    "        # 1. forward\n",
    "        outputs = quantized_net(inputs)\n",
    "        # 2. compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 3. reset parameter gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            ## Calculate validation accuracy\n",
    "            val_acc = accuracy(valloader, quantized_net)\n",
    "\n",
    "            ## Calculate batch accuracy\n",
    "            batch_acc = accuracy_batch(outputs=outputs, labels=labels)\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}, validation accuracy: {val_acc}, batch accuracy: {batch_acc}')\n",
    "\n",
    "            ## Call writer.add_scaler\n",
    "            \n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回の演習ではFunctionクラスを自身で実装して量子化を実装して頂きましたが\\\n",
    "pytorchでは量子化もサポートしているのでもしよければこちらも試してみてください。\n",
    "\n",
    "https://pytorch.org/docs/stable/quantization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終課題\n",
    "それでは、最後に最終課題の説明をします。\\\n",
    "最終課題では、以下の中の一つの変更をニューラルネットワークに適用することで精度がどのように変化するか調査してください。\n",
    "資料提出締め切りは11/22(水) 23:59分です。締め切りまでに発表用のスライドをslackにて提出してください。\n",
    "\n",
    "- データセット変更\n",
    "- 学習データ拡張\n",
    "- Optimizer変更\n",
    "- LR Scheduler追加\n",
    "- モデル変更\n",
    "- バッチサイズと学習速度の関係の調査\n",
    "- 量子化ビット幅変更"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linearresnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
